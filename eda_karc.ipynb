{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS ML Project - Financial Inclusion in Africa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23524, 13)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for zero values\n",
    "zero_count = (df == 0).sum()\n",
    "\n",
    "print(zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for unique values in each column\n",
    "unique_vals = {column: df[column].unique() for column in df.columns}\n",
    "for column, unique_vals in unique_vals.items():\n",
    "    print(f\"Unique values in column {column}: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.uniqueid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have +23k rows but only 8759 unique IDs, which means some people have multiple accounts. Other than removing the duplicate rows, there shouldn't be need for extra cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to Deal with the Duplicates (uniqueid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates \n",
    "df_no_dup = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.uniqueid.value_counts().head(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueidval = 'uniqueid_4393'\n",
    "rows_with_uniqueid = df[df['uniqueid'] == uniqueidval]\n",
    "\n",
    "rows_with_uniqueid.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(bold guess but) I think re-indexing the data and ignoring the old uniqueid should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new unique index \n",
    "df['global_id'] = range(1, len(df) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the old uniqueid column\n",
    "df.drop('uniqueid', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.global_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I convert bank_account column to represent numerical values\n",
    "\n",
    "1: Yes\n",
    "\n",
    "0: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bank_account = df.bank_account.apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df[['global_id','age_of_respondent', 'household_size', 'bank_account']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender vs. Bank Account Ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data= df, x='gender_of_respondent', hue='bank_account')\n",
    "plt.title('Bank Account Ownership by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of age with respect to bank account ownership\n",
    "g = sns.FacetGrid(df, col='bank_account', height=5, aspect=1.5)\n",
    "g.map(plt.hist, 'age_of_respondent', bins=30)\n",
    "g.set_axis_labels('Age of Respondent', 'Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean household size by bank account ownership\n",
    "household_size_stats = df.groupby('bank_account')['household_size'].mean().reset_index()\n",
    "print(household_size_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation of location type and bank account ownership\n",
    "location_cross_tab = pd.crosstab(df['location_type'], df['bank_account'], normalize='index')\n",
    "print(location_cross_tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot of numerical variables\n",
    "sns.pairplot(df, hue='bank_account')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a lot of categorical features, we see a lot of dots in lines, instead of a spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview of numerical feature distribution\n",
    "for column in ['household_size', 'age_of_respondent']:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview of categorical feature distributions\n",
    "for column in ['country', 'year', 'location_type', 'cellphone_access', 'gender_of_respondent',\n",
    "               'relationship_with_head', 'marital_status', 'education_level', 'job_type']:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, x=column)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable Analysis - Bank account 1/0 for yes/no\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='bank_account')\n",
    "plt.title('Distribution of Bank Account Ownership')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Relationships with Target Variable\n",
    "for column in ['country', 'year', 'location_type', 'cellphone_access', 'gender_of_respondent',\n",
    "               'relationship_with_head', 'marital_status', 'education_level', 'job_type']:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, x=column, hue='bank_account')\n",
    "    plt.title(f'Bank Account Ownership by {column}')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix for numerical features \n",
    "numerical_features = ['household_size', 'age_of_respondent']\n",
    "correlation_matrix = df[numerical_features].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No feature seems to have collinearity. Now trying to encode categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['country', 'year', 'location_type', 'cellphone_access',\n",
    "                        'gender_of_respondent', 'relationship_with_head', 'marital_status',\n",
    "                        'education_level', 'job_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "\n",
    "# reformat column names \n",
    "df_encoded.columns = df_encoded.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = [\"country_rwanda\",\n",
    "                    \"country_tanzania\",\n",
    "                    \"country_uganda\",\n",
    "                    \"year_2017\",\n",
    "                    \"year_2018\",\n",
    "                    \"location_type_urban\",\n",
    "                    \"cellphone_access_yes\",\n",
    "                    \"gender_of_respondent_male\",\n",
    "                    \"relationship_with_head_head_of_household\",\n",
    "                    \"relationship_with_head_other_non-relatives\",\n",
    "                    \"relationship_with_head_other_relative\",\n",
    "                    \"relationship_with_head_parent\",\n",
    "                    \"relationship_with_head_spouse\",\n",
    "                    \"marital_status_dont_know\",\n",
    "                    \"marital_status_married/living_together\",\n",
    "                    \"marital_status_single/never_married\",\n",
    "                    \"marital_status_widowed\",\n",
    "                    \"education_level_other/dont_know/rta\",\n",
    "                    \"education_level_primary_education\",\n",
    "                    \"education_level_secondary_education\",\n",
    "                    \"education_level_tertiary_education\",\n",
    "                    \"education_level_vocational/specialised_training\",\n",
    "                    \"job_type_farming_and_fishing\",\n",
    "                    \"job_type_formally_employed_government\",\n",
    "                    \"job_type_formally_employed_private\",\n",
    "                    \"job_type_government_dependent\",\n",
    "                    \"job_type_informally_employed\",\n",
    "                    \"job_type_no_income\",\n",
    "                    \"job_type_other_income\",\n",
    "                    \"job_type_remittance_dependent\",\n",
    "                    \"job_type_self_employed\"\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the boolean columns in encoded_features to integers\n",
    "df_encoded = df_encoded.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix\n",
    "correlation_matrix_enc = df_encoded.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(correlation_matrix_enc, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_numerical_features = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target variable\n",
    "y = df['bank_account']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that there are no NaNs in y\n",
    "assert not np.any(pd.isna(y)), \"Target variable y contains NaN values\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)\n",
    "X = df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.tolist()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection and training\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# maybe try hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models using cross-validation with additional metrics\n",
    "for name, model in models.items():\n",
    "    mae_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring='neg_mean_absolute_error')\n",
    "    accuracy_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    precision_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring='precision')\n",
    "    recall_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring='recall')\n",
    "    f1_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring='f1')\n",
    "    \n",
    "    print(f'{name} MAE: {-mae_scores.mean()}')\n",
    "    print(f'{name} Accuracy: {accuracy_scores.mean()}')\n",
    "    print(f'{name} Precision: {precision_scores.mean()}')\n",
    "    print(f'{name} Recall: {recall_scores.mean()}')\n",
    "    print(f'{name} F1 Score: {f1_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the best model (as an example, using RandomForest here)\n",
    "best_model = RandomForestClassifier()\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate the final model\n",
    "predictions = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model is making constant predictions\n",
    "unique_predictions = np.unique(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE on Test Set: 0.0\n",
      "Random Forest Accuracy on Test Set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# If the model is making constant predictions, we need to re-evaluate the approach\n",
    "if len(unique_predictions) == 1:\n",
    "    print(\"Model is making constant predictions. Re-evaluate the approach.\")\n",
    "else:\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f'Random Forest MAE on Test Set: {mae}')\n",
    "    print(f'Random Forest Accuracy on Test Set: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models using cross-validation\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    print(f'{name} MAE: {-cv_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
